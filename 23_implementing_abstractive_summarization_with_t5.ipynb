{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using T5 for abstractive summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, T5Tokenizer, T5ForConditionalGeneration, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 2.32k/2.32k [00:00<00:00, 14.0MB/s]\n",
      "spiece.model: 100%|██████████| 792k/792k [00:00<00:00, 825kB/s]\n",
      "tokenizer.json: 100%|██████████| 1.39M/1.39M [00:01<00:00, 1.11MB/s]\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "base_model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "base_tokenizer = T5Tokenizer.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96486, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>Great taffy.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This taffy is so good.  It is very soft and ch...</td>\n",
       "      <td>Wonderful, tasty taffy.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Right now I'm mostly just sprouting this so my...</td>\n",
       "      <td>Yay Barley.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a very healthy dog food. Good for thei...</td>\n",
       "      <td>Healthy Dog Food.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good flavor! these came securely packed... the...</td>\n",
       "      <td>fresh and greasy!</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                  Summary  \\\n",
       "0  Great taffy at a great price.  There was a wid...             Great taffy.   \n",
       "1  This taffy is so good.  It is very soft and ch...  Wonderful, tasty taffy.   \n",
       "2  Right now I'm mostly just sprouting this so my...              Yay Barley.   \n",
       "3  This is a very healthy dog food. Good for thei...        Healthy Dog Food.   \n",
       "4  good flavor! these came securely packed... the...        fresh and greasy!   \n",
       "\n",
       "   Score  \n",
       "0      5  \n",
       "1      5  \n",
       "2      5  \n",
       "3      5  \n",
       "4      4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://kaggle.com/snap/amazon-fine-food-reviews?select=Review.csv\n",
    "\n",
    "reviews = pd.read_csv('BERT_LLM/BERT_LLM/data/data/reviews.csv')\n",
    "\n",
    "# Pre-processing step\n",
    "# Punctuation is important in grammar and important for complex decoding architectures to knoe when to stop!\n",
    "def add_punc(s):\n",
    "    if s[-1] not in ('.', '!', '?'):\n",
    "        s = s + '.'\n",
    "    return s\n",
    "\n",
    "reviews.dropna(inplace = True)\n",
    "\n",
    "reviews['Summary'] = reviews['Summary'].map(add_punc)\n",
    "\n",
    "print(reviews.shape)\n",
    "\n",
    "reviews.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13073, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = reviews[(reviews['Summary'].str.len() < 100) & (reviews['Summary'].str.len() >= 30)]\n",
    "\n",
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "\n",
    "reviews_dataset = Dataset.from_pandas(reviews.astype(str).sample(5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a prompt but only as a prefix in the encoder\n",
    "prefix = \"summarize: \"\n",
    "\n",
    "# we will manually add our own labels because unlike GPT, we cannot asseume the labels are based on the inputs\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"Text\"]]\n",
    "    model_inputs = base_tokenizer(inputs, max_length = 1024, truncation = True)\n",
    "\n",
    "    labels = base_tokenizer(examples[\"Summary\"], max_length = 128, truncation = True)\n",
    "\n",
    "    model_inputs['labels'] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    }
   ],
   "source": [
    "tokenized_reviews_dataset = reviews_dataset.map(preprocess_function, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_reviews_dataset = tokenized_reviews_dataset.train_test_split(test_size = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collator specifically for generic sequence to sequence tasks\n",
    "# Use when we are translating one sequence to another like translation, summarization, etc\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer = base_tokenizer, model = base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 01:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'summarization': {'early_stopping': True, 'length_penalty': 2.0, 'max_length': 200, 'min_length': 30, 'no_repeat_ngram_size': 3, 'num_beams': 4, 'prefix': 'summarize: '}, 'translation_en_to_de': {'early_stopping': True, 'max_length': 300, 'num_beams': 4, 'prefix': 'translate English to German: '}, 'translation_en_to_fr': {'early_stopping': True, 'max_length': 300, 'num_beams': 4, 'prefix': 'translate English to French: '}, 'translation_en_to_ro': {'early_stopping': True, 'max_length': 300, 'num_beams': 4, 'prefix': 'translate English to Romanian: '}}\" for key \"task_specific_params\" as a parameter. MLflow's log_param() only accepts values no longer than 250 characters so we dropped this attribute. You can use `MLFLOW_FLATTEN_PARAMS` environment variable to flatten the parameters and avoid this message.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 4.420648097991943,\n",
       " 'eval_runtime': 0.705,\n",
       " 'eval_samples_per_second': 709.248,\n",
       " 'eval_steps_per_second': 22.696}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = './t5_summary_results',\n",
    "    evaluation_strategy = 'epoch',\n",
    "    per_device_train_batch_size = 32,\n",
    "    per_device_eval_batch_size = 32,\n",
    "    num_train_epochs = 20,\n",
    "    load_best_model_at_end = True,\n",
    "    logging_steps = 50,\n",
    "    save_strategy = 'epoch'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = base_model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_reviews_dataset['train'],\n",
    "    eval_dataset = tokenized_reviews_dataset['test'],\n",
    "    data_collator = data_collator,\n",
    ")\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2820' max='2820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2820/2820 05:44, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.698000</td>\n",
       "      <td>3.362388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.508700</td>\n",
       "      <td>3.269763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.426600</td>\n",
       "      <td>3.209758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.294100</td>\n",
       "      <td>3.163584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.263900</td>\n",
       "      <td>3.127627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.192900</td>\n",
       "      <td>3.105354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.195000</td>\n",
       "      <td>3.076183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.141700</td>\n",
       "      <td>3.054890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.107600</td>\n",
       "      <td>3.037829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.041700</td>\n",
       "      <td>3.023930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.007200</td>\n",
       "      <td>3.013276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.970300</td>\n",
       "      <td>3.001168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.992900</td>\n",
       "      <td>2.993779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.982600</td>\n",
       "      <td>2.984126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.980300</td>\n",
       "      <td>2.979317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.970500</td>\n",
       "      <td>2.974134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.955500</td>\n",
       "      <td>2.970676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.959500</td>\n",
       "      <td>2.968519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.886800</td>\n",
       "      <td>2.966870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.940700</td>\n",
       "      <td>2.965942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2820, training_loss=3.129840888706505, metrics={'train_runtime': 345.0947, 'train_samples_per_second': 260.798, 'train_steps_per_second': 8.172, 'total_flos': 1216903603421184.0, 'train_loss': 3.129840888706505, 'epoch': 20.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.9659423828125,\n",
       " 'eval_runtime': 0.7663,\n",
       " 'eval_samples_per_second': 652.475,\n",
       " 'eval_steps_per_second': 20.879,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = T5ForConditionalGeneration.from_pretrained('./t5_summary_results')\n",
    "\n",
    "# summarization pipeline prepends a default prefix of summarize:\n",
    "generator = pipeline(\n",
    "    'summarization', model = loaded_model, tokenizer = base_tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13440    Love the enriched original rice, milk, not pri...\n",
      "Name: Summary, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'We like this item, but wish that it was available in larger sizes, these are way too expensive......'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam = reviews.sample(1)\n",
    "\n",
    "print(sam['Summary'])\n",
    "\n",
    "text = sam['Text'].tolist()[0]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'Great item, but wish it was available in larger sizes.'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a summary\n",
    "generator(text, min_length = 3, max_length = 15, early_stopping = True, num_beams = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'this item is too expensive to find . we like it, but'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try the base t5 on the same text\n",
    "base_generator = pipeline(\n",
    "    'summarization', model = 't5-small', tokenizer = 't5-small'\n",
    ")\n",
    "\n",
    "# Summary is a bit more extractive than our fine-tuned version and style isn't quite the same as our dataset\n",
    "base_generator(text, min_length = 3, max_length = 15, early_stopping = True, num_beams = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a great item, but it is too expensive....\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: trying a different prefix. Not a good result\n",
    "\n",
    "inputs = base_tokenizer(\"not my prompt: \" + text, return_tensors = \"pt\")\n",
    "outputs = loaded_model.generate(\n",
    "    inputs[\"input_ids\"], min_length = 3, max_length = 15\n",
    ")\n",
    "\n",
    "print(base_tokenizer.decode(outputs[0], skip_special_tokens = True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
